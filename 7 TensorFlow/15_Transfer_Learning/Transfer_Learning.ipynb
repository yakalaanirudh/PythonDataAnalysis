{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f82f1cd9-f72a-4607-94f3-79a69078a66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-hub\n",
      "  Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in d:\\programs\\lib\\site-packages (from tensorflow-hub) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in d:\\programs\\lib\\site-packages (from tensorflow-hub) (4.25.3)\n",
      "Collecting tf-keras>=2.14.1 (from tensorflow-hub)\n",
      "  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in d:\\programs\\lib\\site-packages (from tf-keras>=2.14.1->tensorflow-hub) (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in d:\\programs\\lib\\site-packages (from tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\programs\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\programs\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in d:\\programs\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in d:\\programs\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\programs\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\programs\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\programs\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (3.4.0)\n",
      "Requirement already satisfied: packaging in d:\\programs\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (24.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\programs\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.32.3)\n",
      "Requirement already satisfied: setuptools in d:\\programs\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\programs\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\programs\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\programs\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\programs\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\programs\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in d:\\programs\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in d:\\programs\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (3.8.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in d:\\programs\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in d:\\programs\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\programs\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (0.44.0)\n",
      "Requirement already satisfied: rich in d:\\programs\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (13.7.1)\n",
      "Requirement already satisfied: namex in d:\\programs\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (0.0.8)\n",
      "Requirement already satisfied: optree in d:\\programs\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\programs\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\programs\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\programs\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programs\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\programs\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\programs\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\programs\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\programs\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\programs\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\programs\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\programs\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow-hub) (0.1.0)\n",
      "Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl (30 kB)\n",
      "Downloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 1.3/1.7 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 8.6 MB/s eta 0:00:00\n",
      "Installing collected packages: tf-keras, tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.16.1 tf-keras-2.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "738f1cf2-4ea7-49ee-b5d5-bd1144378ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programs\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import PIL.Image as Image\n",
    "import os\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112837a1-0387-4632-b021-aefc092b89ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input image size as 224Ã—224 pixels\n",
    "MobileNetV2 model from TensorFlow Hub expects input images of this shape\n",
    "\n",
    "creates a sequential model in Keras, where layers are stacked one after another\n",
    "\n",
    "adds a pre-trained MobileNetV2 model as a Keras layer.\n",
    "The model URL points to the TensorFlow Hub version of MobileNetV2, a lightweight CNN used for image classification.\n",
    "input_shape=IMAGE_SHAPE+(3,) sets the input shape to (224, 224, 3):\n",
    "224Ã—224 is the image size.\n",
    "3 represents RGB channels (color images).\n",
    "\n",
    "The MobileNetV2 model is pre-trained on ImageNet, a large dataset with 1,000 object classes.\n",
    "Given an image of size (224, 224, 3), the model predicts which of the 1,000 categories the image belongs to.\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "\n",
    "classifier = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\", \n",
    "                   input_shape=IMAGE_SHAPE+(3,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee49ee-e86c-483f-97d0-fcc4796148b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We are opening a goldfish image and resize it to our preset size\n",
    "\"\"\"\n",
    "gold_fish = Image.open(\"goldfish.jpg\").resize(IMAGE_SHAPE)\n",
    "gold_fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09ab46b-ead1-4599-a4bc-8c80411b828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_fish = np.array(gold_fish)/255.0\n",
    "gold_fish.shape\n",
    "#(224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92912967-43e5-4db7-b897-d0fedbbd620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This turns the goldfish images from 3d to 4d (224,224,3) to (1,224,224,3)\n",
    "The new dimenion id batch size since deep learning expects multiple images we add batch size,\n",
    "Here there is only 1 image in this batch, if there are 100 it will be 100\n",
    "\"\"\"\n",
    "gold_fish[np.newaxis, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad23cea-512c-45e3-9985-6049b8a83a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The pretrained model is stored in classifier\n",
    "so we pass this goldfish image to the classifer to know model\n",
    "And the result is a array of probability of each class for this image so it is 1*1000 shape\n",
    "From these arguments we select the amx arg and get its index\n",
    "\"\"\"\n",
    "result = classifier.predict(gold_fish[np.newaxis, ...])\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4521f45-50d8-477d-ace3-a9ce731013f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label_index = np.argmax(result)\n",
    "predicted_label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbf8dfe-8c9b-45f0-80a8-f5b92b61b814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
    "\"\"\"\n",
    "The above Downloads the ImageNet class labels (1,000 categories) from TensorFlow's official storage and stores it in ImageNetLabels.txt file\n",
    "\n",
    "We open and read that file \n",
    "\n",
    "We get the first 5 indexes with highest probabilities and  later we get the index with highest probability\n",
    "\"\"\"\n",
    "image_labels = []\n",
    "with open(\"ImageNetLabels.txt\", \"r\") as f:\n",
    "    image_labels = f.read().splitlines()\n",
    "image_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a2b9c0-7719-4b5c-8a80-a5864bbd4f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_labels[predicted_label_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189a1e62-6d41-4783-8f99-169a3f687ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load flowers dataset\n",
    "\n",
    "\"\"\"\n",
    "pathlib gives an windows path object \n",
    "\"\"\"\n",
    "\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url,  cache_dir='.', untar=True)\n",
    "# cache_dir indicates where to download data. I specified . which means current directory in which there will be a flower_photos folder\n",
    "# untar true will unzip it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc68abbf-062c-4a80-898c-f4e19f9d84e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b65d68-bd4d-4556-91ba-1baec5350bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0c0b5c-4525-459e-b211-dfb383952db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data_dir.glob('*/*.jpg'))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01b7137-1f2f-4b7f-8c1a-df65cc960dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04105f67-09e8-44f8-8c60-a90255e9d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "roses = list(data_dir.glob('roses/*'))\n",
    "roses[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5d3b6a-8807-417e-bdee-27b74264b229",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.open(str(roses[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76177feb-c582-4689-aecf-40d69c278350",
   "metadata": {},
   "outputs": [],
   "source": [
    "tulips = list(data_dir.glob('tulips/*'))\n",
    "PIL.Image.open(str(tulips[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dbf32d-ee14-4dea-afa3-112369e51cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read flowers images from disk into numpy array using opencv\n",
    "\"\"\"\n",
    "flowers_images_dict stores image file paths for different flower categories.\n",
    "It uses data_dir.glob('category/*') to get all images in each folder.\n",
    "\"\"\"\n",
    "flowers_images_dict = {\n",
    "    'roses': list(data_dir.glob('roses/*')),\n",
    "    'daisy': list(data_dir.glob('daisy/*')),\n",
    "    'dandelion': list(data_dir.glob('dandelion/*')),\n",
    "    'sunflowers': list(data_dir.glob('sunflowers/*')),\n",
    "    'tulips': list(data_dir.glob('tulips/*')),\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "This dictionary assigns a numeric label (integer) to each flower category. \n",
    "It is used for classification tasks where models require numerical labels instead of text\n",
    "\"\"\"\n",
    "flowers_labels_dict = {\n",
    "    'roses': 0,\n",
    "    'daisy': 1,\n",
    "    'dandelion': 2,\n",
    "    'sunflowers': 3,\n",
    "    'tulips': 4,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1abe82f-7cfd-4940-8cfc-4f693fdb07b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowers_images_dict['roses'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c4932a-3fa3-45b3-835a-fc7f348e397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(flowers_images_dict['roses'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8246d6-c30e-4c11-963e-e4f504b400d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(str(flowers_images_dict['roses'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a962d23-f164-4e53-bdbe-10c16e81e6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30a0f8b-b974-4bed-87ac-11ed855132f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.resize(img,(224,224)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e567cf6c-2689-4404-99fc-78baa7fde99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "X (Features/Input Data) â†’ A list to store image arrays.\n",
    "y (Labels/Target Data) â†’ A list to store corresponding numeric labels from flowers_labels_dict.\n",
    "\n",
    "Flower name is the subfolder, for that subfolder and all its images then iterat ethrough images\n",
    "\"\"\"\n",
    "X, y = [], []\n",
    "\n",
    "for flower_name, images in flowers_images_dict.items():\n",
    "    for image in images:\n",
    "        img = cv2.imread(str(image))\n",
    "        resized_img = cv2.resize(img,(224,224))\n",
    "        X.append(resized_img)\n",
    "        y.append(flowers_labels_dict[flower_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2865d2-cf60-4ee9-803f-88ab7ed1a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586c41de-12ba-4529-89a0-8a593dccfd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268241f8-8ed8-4edb-b3b2-dbdeff05edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing: scale images\n",
    "\n",
    "X_train_scaled = X_train / 255\n",
    "X_test_scaled = X_test / 255\n",
    "\n",
    "#Make prediction using pre-trained model on new flowers dataset\n",
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d2fae0-ad2b-4ef5-992c-092071f226e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE+(3,)\n",
    "\n",
    "\"\"\"\n",
    "IMAGE SHAPE IS 224/224 so by doing this we do 224/224/3\n",
    "\"\"\"\n",
    "\n",
    "x0_resized = cv2.resize(X[0], IMAGE_SHAPE)\n",
    "x1_resized = cv2.resize(X[1], IMAGE_SHAPE)\n",
    "x2_resized = cv2.resize(X[2], IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1883b82-8e26-408b-abf6-9c9c2a95f67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('off')\n",
    "plt.imshow(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b99ccf7-56d5-4ba6-8ac9-5acc60e06b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('off')\n",
    "plt.imshow(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440723e7-aa03-41f3-924d-a344a4d641dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('off')\n",
    "plt.imshow(X[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603b6ab3-b3f9-4040-a7a8-f6efb031e9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = classifier.predict(np.array([x0_resized, x1_resized, x2_resized]))\n",
    "predicted = np.argmax(predicted, axis=1)\n",
    "predicted\n",
    "\n",
    "#The variable predicted gives the class name from the pretrained 1000 classes here it predicts shower curatin\n",
    "\n",
    "\"\"\"\n",
    "image_labels[795] gives shower curtain\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99b3b90-ddb1-4cf3-aebe-fce737e55200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now take pre-trained model and retrain it using flowers images\n",
    "\"\"\"\n",
    "Load a pretrained MobileNetV2 model from TensorFlow Hub, removes its final layer, \n",
    "and freeze the rest layers  without changing weights\n",
    "so it can be used as a feature extractor.\n",
    "You can then add your own classification head to train a custom model.\n",
    "\n",
    "Means we add our own final layer\n",
    "\n",
    "In the pretrained model, let's say we have 5 layers (0,1,2,3,4):\n",
    "\n",
    "Layers 0 to 3 â†’ Frozen (weights donâ€™t change).\n",
    "Layer 4 â†’ Removed (it was trained for another task, like ImageNet classification).\n",
    "New Layer 4 â†’ Added (custom classification layer for your dataset).\n",
    "\n",
    "Loads the MobileNetV2 model as a Keras layer.\n",
    "It acts as a feature extractor (removing the last classification layer).\n",
    "input_shape=(224, 224, 3)\n",
    "\n",
    "Specifies that the input images must be 224Ã—224 pixels with 3 color channels (RGB).\n",
    "This is the standard size for MobileNetV2.\n",
    "trainable=False\n",
    "\n",
    "Freezes the model's weights (no updates during training).\n",
    "This means that the pretrained features will be used without modification.\n",
    "This helps prevent overfitting when training on a small dataset.\n",
    "\"\"\"\n",
    "\n",
    "feature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "\n",
    "pretrained_model_without_top_layer = hub.KerasLayer(\n",
    "    feature_extractor_model, input_shape=(224, 224, 3), trainable=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0b3524-906c-48da-b027-bff0415818cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_of_flowers = 5\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  pretrained_model_without_top_layer,\n",
    "  tf.keras.layers.Dense(num_of_flowers)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d0a4aa-1d00-4cf8-9481-91e80f7553af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=\"adam\",\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['acc'])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b8d39f-423e-4258-a831-c1bf87afc7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We can see that this has better accuarcy as this model is based on a model trained on a million images\n",
    "\"\"\"\n",
    "model.evaluate(X_test_scaled,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
