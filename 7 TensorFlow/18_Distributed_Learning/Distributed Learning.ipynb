{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadf195e-56f0-403c-a110-5330b7e4c05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ecbc3b-2da3-4092-90a4-191594bd432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "# Version Information\n",
    "# tensorflow 2.2.0 , Cudnn7.6.5 and Cuda 10.1 , python 3.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb4ae67-da12-4865-ae27-3259729ef063",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This command shows list of physical devices available for tensorflow\n",
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874bc8f7-ff53-4f7c-b10f-33a59e903a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c65d64-3d0f-4cdb-a131-35a90bf339f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90522e3-b374-490f-88be-ec894f5b9fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the dataset\n",
    "Our dataset contains 60000 small training images that belongs to one of the below 10 classes\n",
    "\"\"\"\n",
    "(X_train, y_train), (X_test,y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b50062e-9ee6-4518-9521-c6b41ba2bd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293d5878-ac78-41b2-ab3d-c07cff456b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fec8927-a589-4afc-ab34-2e1fc89a8a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf3cca0-229e-4ebc-a90a-3dd803e03ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes[y_train[3][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46668047-17af-42f2-a555-eee919ef2c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96bf9fc-1921-414c-9671-4db411959c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c70a96a-13e1-48ec-84a2-0200c646e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccde517-d57f-4eda-a4d9-0db54a130c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing: Scale images\n",
    "\n",
    "X_train_scaled = X_train / 255\n",
    "X_test_scaled = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d48f87-2966-4ee3-a6fa-4f244bc6e660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoded format\n",
    "y_train_categorical = keras.utils.to_categorical(\n",
    "    y_train, num_classes=10, dtype='float32'\n",
    ")\n",
    "y_test_categorical = keras.utils.to_categorical(\n",
    "    y_test, num_classes=10, dtype='float32'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052fd09c-1b8e-4b19-9739-5ef1770c8bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e757cee-853b-4070-88e1-08a7614af233",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_categorical[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f996311-8f1e-4e13-89f0-939589ec0929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model building and training\n",
    "\n",
    "def get_model():\n",
    "    model = keras.Sequential([\n",
    "            keras.layers.Flatten(input_shape=(32,32,3)),\n",
    "            keras.layers.Dense(3000, activation='relu'),\n",
    "            keras.layers.Dense(1000, activation='relu'),\n",
    "            keras.layers.Dense(10, activation='sigmoid')    \n",
    "        ])\n",
    "\n",
    "    model.compile(optimizer='SGD',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f860c213-abc1-41e5-afc8-6482fc2c7425",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf_dataset = tf.data.Dataset.from_tensor_slices((X_train_scaled, y_train_categorical))\n",
    "test_tf_dataset = tf.data.Dataset.from_tensor_slices((X_test_scaled, y_test_categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcbd050-dc8b-4125-9bfb-bf253f707df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This line initializes a MirroredStrategy, which is a data parallelism strategy in TensorFlow for multi-GPU training.\n",
    "\n",
    "Where the bathch size is split across the multiple gpus\n",
    "\"\"\"\n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad805cb-1379-4d16-b8ea-085b3dc16ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy.num_replicas_in_sync  #4 Here we have four GPUs so we split data into 4 parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040dbc18-0cfa-49c7-a686-1b31229889e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Each replica deals with 250 images four cores so total batchzie is 1000\n",
    "Autotune lets the tensorflow know how many samples it needs to prefetch for the next iteration\n",
    "\"\"\"\n",
    "BATCH_SIZE_PER_REPLICA = 250\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "\n",
    "\n",
    "train_dataset = train_tf_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_tf_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448d5d06-3bbd-45cc-9c16-3e00f0cab186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measure training time on a GPU\n",
    "%%timeit -n1 -r1 \n",
    "with strategy.scope():\n",
    "    gpu_model = get_model()\n",
    "    gpu_model.fit(train_dataset, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39845d83-5741-4870-8ad7-9f1a22dd0d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measure training time on a CPU\n",
    "%%timeit -n1 -r1 \n",
    "with tf.device('/CPU:0'):\n",
    "    cpu_model = get_model()\n",
    "    cpu_model.fit(train_dataset, epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
